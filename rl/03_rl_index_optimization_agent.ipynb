{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "409c6273-810c-4ebf-bf77-48cd99b527ea",
   "metadata": {},
   "source": [
    "# ðŸ§  RL Index Optimization Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42e884-136e-4e58-a4bd-25a6f261ed74",
   "metadata": {},
   "source": [
    "## RL State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0fec542-19cb-44fa-864a-5fd468dcf334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "#  Imports and constants\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Actions\n",
    "ACTION_DO_NOTHING = 0\n",
    "ACTION_ADD_INDEX = 1\n",
    "ACTION_REMOVE_INDEX = 2\n",
    "NUM_ACTIONS = 3\n",
    "\n",
    "# State features\n",
    "state_features = [\n",
    "    \"rows_examined\",\n",
    "    \"joins\",\n",
    "    \"tables_count\",\n",
    "    \"query_length\",\n",
    "    \"cpu_usage\",\n",
    "    \"memory_usage\"\n",
    "]\n",
    "\n",
    "# Load dataset\n",
    "df_rl = pd.read_csv(\"../data/ml_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad14597-19bf-4b7e-a451-3264893cc431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_time</th>\n",
       "      <th>rows_examined</th>\n",
       "      <th>joins</th>\n",
       "      <th>has_sum</th>\n",
       "      <th>has_group_by</th>\n",
       "      <th>has_where</th>\n",
       "      <th>tables_count</th>\n",
       "      <th>query_length</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>is_slow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.046609</td>\n",
       "      <td>71500.254714</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>35.487143</td>\n",
       "      <td>0.691010</td>\n",
       "      <td>191.063795</td>\n",
       "      <td>0.315048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031961</td>\n",
       "      <td>113014.744349</td>\n",
       "      <td>0.451765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451765</td>\n",
       "      <td>0.451765</td>\n",
       "      <td>4.130142</td>\n",
       "      <td>7.722702</td>\n",
       "      <td>1.015428</td>\n",
       "      <td>0.464546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.018242</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190.453125</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.024632</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190.453125</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.028639</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190.527344</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.078004</td>\n",
       "      <td>250188.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>191.317383</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.229350</td>\n",
       "      <td>250188.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>194.011719</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         query_time  rows_examined         joins  has_sum  has_group_by  \\\n",
       "count  21000.000000   21000.000000  21000.000000  21000.0       21000.0   \n",
       "mean       0.046609   71500.254714      1.714286      1.0           1.0   \n",
       "std        0.031961  113014.744349      0.451765      0.0           0.0   \n",
       "min        0.018242       5.000000      1.000000      1.0           1.0   \n",
       "25%        0.024632      18.000000      1.000000      1.0           1.0   \n",
       "50%        0.028639      32.000000      2.000000      1.0           1.0   \n",
       "75%        0.078004  250188.000000      2.000000      1.0           1.0   \n",
       "max        0.229350  250188.000000      2.000000      1.0           1.0   \n",
       "\n",
       "          has_where  tables_count  query_length     cpu_usage  memory_usage  \\\n",
       "count  21000.000000  21000.000000  21000.000000  21000.000000  21000.000000   \n",
       "mean       0.714286      2.714286     35.487143      0.691010    191.063795   \n",
       "std        0.451765      0.451765      4.130142      7.722702      1.015428   \n",
       "min        0.000000      2.000000     30.000000      0.000000    190.453125   \n",
       "25%        0.000000      2.000000     33.000000      0.000000    190.453125   \n",
       "50%        1.000000      3.000000     33.000000      0.000000    190.527344   \n",
       "75%        1.000000      3.000000     42.000000      0.000000    191.317383   \n",
       "max        1.000000      3.000000     42.000000    100.000000    194.011719   \n",
       "\n",
       "            is_slow  \n",
       "count  21000.000000  \n",
       "mean       0.315048  \n",
       "std        0.464546  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rl.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c428f5e-c1d2-4a29-8489-b33ce595f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "# Action constants\n",
    "ACTION_DO_NOTHING = 0\n",
    "ACTION_ADD_INDEX = 1\n",
    "ACTION_REMOVE_INDEX = 2\n",
    "NUM_ACTIONS = 3\n",
    "\n",
    "\n",
    "class IndexOptimizationEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    RL Environment for Index Optimization (Realistic & Balanced)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, state_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.state_features = state_features\n",
    "\n",
    "        # Observation space\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=(len(state_features),),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Action space\n",
    "        self.action_space = spaces.Discrete(NUM_ACTIONS)\n",
    "        self.action_meaning = {\n",
    "            0: \"DO_NOTHING\",\n",
    "            1: \"ADD_INDEX\",\n",
    "            2: \"REMOVE_INDEX\"\n",
    "        }\n",
    "\n",
    "        # Data-driven thresholds\n",
    "        self.slow_threshold = 0.08     # top 25% slow\n",
    "        self.fast_threshold = 0.03     # very fast queries\n",
    "        self.memory_threshold = 192.0  # high memory usage\n",
    "\n",
    "        self.current_step = 0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_step = np.random.randint(0, len(self.df))\n",
    "        state = self.df.loc[self.current_step, self.state_features].astype(np.float32).values\n",
    "        return state, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        row = self.df.loc[self.current_step]\n",
    "        base_time = float(row[\"query_time\"])\n",
    "        memory = float(row[\"memory_usage\"])\n",
    "\n",
    "        # ---- Simulate action effect ----\n",
    "        if action == ACTION_ADD_INDEX:\n",
    "            new_time = base_time * np.random.uniform(0.65, 0.85)\n",
    "\n",
    "        elif action == ACTION_REMOVE_INDEX:\n",
    "            if base_time < self.fast_threshold and memory > self.memory_threshold:\n",
    "                # Safe index removal\n",
    "                new_time = base_time * np.random.uniform(0.95, 1.0)\n",
    "            else:\n",
    "                # Harmful index removal\n",
    "                new_time = base_time * np.random.uniform(1.05, 1.25)\n",
    "\n",
    "        else:  # DO_NOTHING\n",
    "            new_time = base_time\n",
    "\n",
    "        # ---- Reward calculation (SINGLE source of truth) ----\n",
    "        improvement = (base_time - new_time) / base_time\n",
    "\n",
    "        reward = improvement\n",
    "\n",
    "        # Penalties / bonuses\n",
    "        if action == ACTION_DO_NOTHING and base_time > self.slow_threshold:\n",
    "            reward -= 0.05\n",
    "\n",
    "        if action == ACTION_REMOVE_INDEX and new_time > base_time:\n",
    "            reward -= 0.1\n",
    "\n",
    "        if action == ACTION_ADD_INDEX and base_time < self.fast_threshold:\n",
    "            reward -= 0.05\n",
    "\n",
    "        terminated = True\n",
    "        truncated = False\n",
    "\n",
    "        next_state = row[self.state_features].astype(np.float32).values\n",
    "        return next_state, reward, terminated, truncated, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83c829b-3af8-4c26-a300-c5bce53cbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./rl_tensorboard/PPO_4\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 0.000433 |\n",
      "| time/              |          |\n",
      "|    fps             | 529      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 0.0253     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 417        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04305301 |\n",
      "|    clip_fraction        | 0.595      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | -8.65      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0394    |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0599    |\n",
      "|    value_loss           | 0.0462     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 0.0819      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045811933 |\n",
      "|    clip_fraction        | 0.934       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.944      |\n",
      "|    explained_variance   | -0.00998    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.146      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.156      |\n",
      "|    value_loss           | 0.0327      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 0.174      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 377        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 21         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07526702 |\n",
      "|    clip_fraction        | 0.953      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.689     |\n",
      "|    explained_variance   | -0.0199    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.154     |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.163     |\n",
      "|    value_loss           | 0.0317     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 0.175       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.099084884 |\n",
      "|    clip_fraction        | 0.901       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.359      |\n",
      "|    explained_variance   | -0.035      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.123      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.142      |\n",
      "|    value_loss           | 0.0244      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 0.224      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 374        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25471795 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0876    |\n",
      "|    explained_variance   | -0.00819   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0515    |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.07      |\n",
      "|    value_loss           | 0.0132     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 0.224        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008952296 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0233      |\n",
      "|    explained_variance   | 0.0569       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00794     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 0.00404      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 0.214        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.714621e-05 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0168      |\n",
      "|    explained_variance   | 0.0361       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00261      |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    value_loss           | 0.004        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 0.226         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 374           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 49            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4151773e-05 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0131       |\n",
      "|    explained_variance   | 0.0571        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00211       |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000291     |\n",
      "|    value_loss           | 0.00372       |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1              |\n",
      "|    ep_rew_mean          | 0.225          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 373            |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 54             |\n",
      "|    total_timesteps      | 20480          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000101023295 |\n",
      "|    clip_fraction        | 0.00083        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00882       |\n",
      "|    explained_variance   | -0.00148       |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 0.00194        |\n",
      "|    n_updates            | 90             |\n",
      "|    policy_gradient_loss | -0.000756      |\n",
      "|    value_loss           | 0.00391        |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 0.222         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 372           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 60            |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018747008 |\n",
      "|    clip_fraction        | 0.00132       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00591      |\n",
      "|    explained_variance   | 0.0747        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00209       |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.000735     |\n",
      "|    value_loss           | 0.00361       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 0.219         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 371           |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 66            |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5331741e-05 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00472      |\n",
      "|    explained_variance   | 0.0747        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00172       |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.000355     |\n",
      "|    value_loss           | 0.00362       |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.218     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 372       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00461  |\n",
      "|    explained_variance   | 0.0797    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00161   |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -2.02e-07 |\n",
      "|    value_loss           | 0.00379   |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 0.223        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 372          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.619492e-05 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00377     |\n",
      "|    explained_variance   | 0.0242       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00171      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000493    |\n",
      "|    value_loss           | 0.00391      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 0.225        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 372          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.431631e-05 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0029      |\n",
      "|    explained_variance   | -0.0511      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00163      |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000809    |\n",
      "|    value_loss           | 0.00402      |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.22      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 371       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00286  |\n",
      "|    explained_variance   | 0.0783    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00188   |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -2.62e-08 |\n",
      "|    value_loss           | 0.00382   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.226     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 371       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 93        |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00286  |\n",
      "|    explained_variance   | 0.056     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00188   |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -6.51e-08 |\n",
      "|    value_loss           | 0.00386   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.219     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 371       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00286  |\n",
      "|    explained_variance   | 0.0833    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00203   |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -1.96e-07 |\n",
      "|    value_loss           | 0.00375   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 0.225    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 371      |\n",
      "|    iterations           | 19       |\n",
      "|    time_elapsed         | 104      |\n",
      "|    total_timesteps      | 38912    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00285 |\n",
      "|    explained_variance   | 0.0423   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00144  |\n",
      "|    n_updates            | 180      |\n",
      "|    policy_gradient_loss | -6.7e-07 |\n",
      "|    value_loss           | 0.0035   |\n",
      "--------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1              |\n",
      "|    ep_rew_mean          | 0.224          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 371            |\n",
      "|    iterations           | 20             |\n",
      "|    time_elapsed         | 110            |\n",
      "|    total_timesteps      | 40960          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000113417744 |\n",
      "|    clip_fraction        | 0.000439       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00183       |\n",
      "|    explained_variance   | 0.0667         |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 0.00189        |\n",
      "|    n_updates            | 190            |\n",
      "|    policy_gradient_loss | -0.000268      |\n",
      "|    value_loss           | 0.00385        |\n",
      "--------------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 0.218    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 371      |\n",
      "|    iterations           | 21       |\n",
      "|    time_elapsed         | 115      |\n",
      "|    total_timesteps      | 43008    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00173 |\n",
      "|    explained_variance   | 0.0457   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00177  |\n",
      "|    n_updates            | 200      |\n",
      "|    policy_gradient_loss | -1.1e-07 |\n",
      "|    value_loss           | 0.00386  |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 0.214         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 370           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 121           |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013618844 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00107      |\n",
      "|    explained_variance   | 0.0562        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00194       |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -0.000425     |\n",
      "|    value_loss           | 0.00397       |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.212     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 368       |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 127       |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00105  |\n",
      "|    explained_variance   | 0.075     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00206   |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -2.39e-08 |\n",
      "|    value_loss           | 0.00383   |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 0.228         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 368           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 133           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025988853 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000603     |\n",
      "|    explained_variance   | 0.0692        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00186       |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.000679     |\n",
      "|    value_loss           | 0.0037        |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.208     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 369       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 138       |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000577 |\n",
      "|    explained_variance   | 0.0843    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00206   |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -5.77e-09 |\n",
      "|    value_loss           | 0.00383   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.228     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 369       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 144       |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00058  |\n",
      "|    explained_variance   | 0.0659    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00196   |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -2.59e-08 |\n",
      "|    value_loss           | 0.00367   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.221     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 368       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 149       |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000584 |\n",
      "|    explained_variance   | 0.0354    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00142   |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -8.05e-08 |\n",
      "|    value_loss           | 0.0037    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.221     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 367       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 156       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000571 |\n",
      "|    explained_variance   | 0.0497    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00202   |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -5.72e-08 |\n",
      "|    value_loss           | 0.00373   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.227     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 362       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 163       |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000571 |\n",
      "|    explained_variance   | 0.0684    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00164   |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -3.21e-08 |\n",
      "|    value_loss           | 0.00383   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.216     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 361       |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 169       |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000568 |\n",
      "|    explained_variance   | 0.0637    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00177   |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -1.01e-08 |\n",
      "|    value_loss           | 0.0037    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.203     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 360       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 176       |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000568 |\n",
      "|    explained_variance   | 0.0727    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00204   |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -3.61e-08 |\n",
      "|    value_loss           | 0.0037    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.22      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 356       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 183       |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000568 |\n",
      "|    explained_variance   | 0.0792    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0015    |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -2.05e-09 |\n",
      "|    value_loss           | 0.00358   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.221     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 351       |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 192       |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000564 |\n",
      "|    explained_variance   | 0.0826    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00256   |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -8.21e-09 |\n",
      "|    value_loss           | 0.00381   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.227     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 345       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 201       |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000578 |\n",
      "|    explained_variance   | 0.012     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00196   |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -2.05e-07 |\n",
      "|    value_loss           | 0.00378   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.23      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 341       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 210       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00059  |\n",
      "|    explained_variance   | 0.0778    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00178   |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -1.74e-08 |\n",
      "|    value_loss           | 0.00372   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.236     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 337       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 218       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000582 |\n",
      "|    explained_variance   | 0.0684    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00195   |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -7.45e-08 |\n",
      "|    value_loss           | 0.00383   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.226     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 331       |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 228       |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000563 |\n",
      "|    explained_variance   | 0.0969    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0017    |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | -6.43e-08 |\n",
      "|    value_loss           | 0.00378   |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 0.226         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 328           |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 237           |\n",
      "|    total_timesteps      | 77824         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025386267 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000286     |\n",
      "|    explained_variance   | 0.0676        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00186       |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | -0.000237     |\n",
      "|    value_loss           | 0.00365       |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.236     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 318       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 250       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000262 |\n",
      "|    explained_variance   | 0.0396    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00165   |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | 2.11e-10  |\n",
      "|    value_loss           | 0.00376   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.22      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 313       |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 261       |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000266 |\n",
      "|    explained_variance   | 0.0765    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00134   |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | -1.96e-09 |\n",
      "|    value_loss           | 0.00369   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.228     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 310       |\n",
      "|    iterations           | 41        |\n",
      "|    time_elapsed         | 270       |\n",
      "|    total_timesteps      | 83968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000265 |\n",
      "|    explained_variance   | 0.0659    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00145   |\n",
      "|    n_updates            | 400       |\n",
      "|    policy_gradient_loss | -8.87e-09 |\n",
      "|    value_loss           | 0.00368   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.224     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 309       |\n",
      "|    iterations           | 42        |\n",
      "|    time_elapsed         | 277       |\n",
      "|    total_timesteps      | 86016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000265 |\n",
      "|    explained_variance   | 0.11      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00208   |\n",
      "|    n_updates            | 410       |\n",
      "|    policy_gradient_loss | -6.87e-10 |\n",
      "|    value_loss           | 0.00361   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.222     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 309       |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 284       |\n",
      "|    total_timesteps      | 88064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000262 |\n",
      "|    explained_variance   | 0.066     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.002     |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | -1.19e-08 |\n",
      "|    value_loss           | 0.00372   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.203     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 308       |\n",
      "|    iterations           | 44        |\n",
      "|    time_elapsed         | 291       |\n",
      "|    total_timesteps      | 90112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000264 |\n",
      "|    explained_variance   | 0.0682    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00164   |\n",
      "|    n_updates            | 430       |\n",
      "|    policy_gradient_loss | -1.99e-08 |\n",
      "|    value_loss           | 0.00389   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.223     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 308       |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 299       |\n",
      "|    total_timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000264 |\n",
      "|    explained_variance   | 0.0882    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00182   |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | -3.02e-09 |\n",
      "|    value_loss           | 0.00364   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.223     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 305       |\n",
      "|    iterations           | 46        |\n",
      "|    time_elapsed         | 308       |\n",
      "|    total_timesteps      | 94208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000268 |\n",
      "|    explained_variance   | 0.087     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00185   |\n",
      "|    n_updates            | 450       |\n",
      "|    policy_gradient_loss | -3.22e-09 |\n",
      "|    value_loss           | 0.00388   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.225     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 304       |\n",
      "|    iterations           | 47        |\n",
      "|    time_elapsed         | 316       |\n",
      "|    total_timesteps      | 96256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00027  |\n",
      "|    explained_variance   | 0.0717    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00259   |\n",
      "|    n_updates            | 460       |\n",
      "|    policy_gradient_loss | -1.24e-08 |\n",
      "|    value_loss           | 0.00404   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.232     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 303       |\n",
      "|    iterations           | 48        |\n",
      "|    time_elapsed         | 324       |\n",
      "|    total_timesteps      | 98304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000271 |\n",
      "|    explained_variance   | 0.0753    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00201   |\n",
      "|    n_updates            | 470       |\n",
      "|    policy_gradient_loss | -2.22e-08 |\n",
      "|    value_loss           | 0.00372   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.221     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 297       |\n",
      "|    iterations           | 49        |\n",
      "|    time_elapsed         | 337       |\n",
      "|    total_timesteps      | 100352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000266 |\n",
      "|    explained_variance   | 0.0595    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00166   |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | -2.66e-08 |\n",
      "|    value_loss           | 0.00386   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1f7032d47d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = IndexOptimizationEnv(df_rl, state_features)\n",
    "\n",
    "# Initialize PPO agent\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./rl_tensorboard/\"\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=100000)\n",
    "# I tested with a 1.000.000 step same result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531ad178-051f-4929-9028-e40bddf81484",
   "metadata": {},
   "source": [
    "## what is the Chosen Action the Agen will take "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a4fb82c-ae10-4a1d-9869-9339082be3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen action: 1\n",
      "Action meaning: ADD_INDEX\n"
     ]
    }
   ],
   "source": [
    "state, _ = env.reset()\n",
    "action, _ = model.predict(state, deterministic=True)\n",
    "\n",
    "action_int = int(action)  \n",
    "\n",
    "print(\"Chosen action:\", action_int)\n",
    "print(\"Action meaning:\", env.action_meaning[action_int])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf9a48-d485-4069-afc3-350eb171aa0a",
   "metadata": {},
   "source": [
    "# Multi-episode evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a88b8d0-afc0-4590-b1e0-a1111e544a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Episode_1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode_2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode_3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode_4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode_5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode_20996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode_20997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode_20998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode_20999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode_21000</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "Episode_1      0\n",
       "Episode_2      1\n",
       "Episode_3      0\n",
       "Episode_4      0\n",
       "Episode_5      0\n",
       "...           ..\n",
       "Episode_20996  0\n",
       "Episode_20997  1\n",
       "Episode_20998  1\n",
       "Episode_20999  0\n",
       "Episode_21000  1\n",
       "\n",
       "[21000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Log all chosen actions for 50 episodes\n",
    "# -----------------------------\n",
    "episodes = 21000\n",
    "all_actions = []\n",
    "\n",
    "for ep in range(episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    ep_actions = []\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = model.predict(state, deterministic=True)\n",
    "        action = int(action)\n",
    "        \n",
    "        # Safety\n",
    "        if state[0] < 1000 and action == ACTION_ADD_INDEX:\n",
    "            action = ACTION_DO_NOTHING\n",
    "\n",
    "        ep_actions.append(action)\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated\n",
    "\n",
    "    all_actions.append(ep_actions)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_all_actions = pd.DataFrame(all_actions).fillna(-1).astype(int)\n",
    "df_all_actions.index = [f\"Episode_{i+1}\" for i in range(episodes)]\n",
    "df_all_actions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371d693e-4cbb-4d1e-9a96-0f07722c501e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 15012, 1: 5988, 2: 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "flat_actions = [a for ep_actions in all_actions for a in ep_actions]\n",
    "\n",
    "counts = Counter(flat_actions)\n",
    "\n",
    "action_summary = {\n",
    "    0: counts.get(0, 0),  # DO_NOTHING\n",
    "    1: counts.get(1, 0),  # ADD_INDEX\n",
    "    2: counts.get(2, 0),  # REMOVE_INDEX\n",
    "}\n",
    "\n",
    "action_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66318045-cc49-4a7a-a227-4ab91bfb836c",
   "metadata": {},
   "source": [
    "## Policy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f1d6e6f-d7c5-4f3d-bbc8-744b4402fff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 0.22128134760210524\n",
      "Mean improvement: 0.22128134760210477\n"
     ]
    }
   ],
   "source": [
    "episodes = 21000\n",
    "total_reward = 0\n",
    "improvements = []\n",
    "\n",
    "for _ in range(episodes):\n",
    "    state, _ = env.reset()\n",
    "    action, _ = model.predict(state, deterministic=True)\n",
    "    action = int(action)\n",
    "\n",
    "    row = env.df.loc[env.current_step]\n",
    "    base_time = row[\"query_time\"]\n",
    "\n",
    "    _, reward, _, _, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "    improvements.append(reward)\n",
    "\n",
    "print(\"Average reward:\", total_reward / episodes)\n",
    "print(\"Mean improvement:\", np.mean(improvements))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be0687-86ea-4397-8244-e8a1414e58f9",
   "metadata": {},
   "source": [
    "## Human vs RL comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55c2f947-ac91-4d06-87f4-6e8850572ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL vs Human agreement rate: 0.23604761904761903\n"
     ]
    }
   ],
   "source": [
    "def human_dba_decision(row):\n",
    "    return ACTION_ADD_INDEX if row[\"query_time\"] > 0.08 else ACTION_DO_NOTHING\n",
    "\n",
    "matches = 0\n",
    "\n",
    "for _ in range(21000):\n",
    "    state, _ = env.reset()\n",
    "    row = env.df.loc[env.current_step]\n",
    "\n",
    "    rl_action, _ = model.predict(state, deterministic=True)\n",
    "    rl_action = int(rl_action)\n",
    "\n",
    "    human_action = human_dba_decision(row)\n",
    "\n",
    "    if rl_action == human_action:\n",
    "        matches += 1\n",
    "\n",
    "print(\"RL vs Human agreement rate:\", matches / 21000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6de602-6e21-4a71-a25a-bc4781593d08",
   "metadata": {},
   "source": [
    "## Average reward comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52ea244-aa03-4c40-824f-f141166f702b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human avg reward: 0.05467825351931967\n",
      "RL avg reward: 0.21985677736615758\n"
     ]
    }
   ],
   "source": [
    "human_rewards = []\n",
    "rl_rewards = []\n",
    "\n",
    "for _ in range(500):\n",
    "    state, _ = env.reset()\n",
    "    row = env.df.loc[env.current_step]\n",
    "\n",
    "    # Human\n",
    "    human_action = human_dba_decision(row)\n",
    "    _, r_human, _, _, _ = env.step(human_action)\n",
    "\n",
    "    # RL\n",
    "    rl_action, _ = model.predict(state, deterministic=True)\n",
    "    rl_action = int(rl_action)\n",
    "    _, r_rl, _, _, _ = env.step(rl_action)\n",
    "\n",
    "    human_rewards.append(r_human)\n",
    "    rl_rewards.append(r_rl)\n",
    "\n",
    "print(\"Human avg reward:\", np.mean(human_rewards))\n",
    "print(\"RL avg reward:\", np.mean(rl_rewards))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446c191-3cfa-44d1-ba4d-f0b7f040047d",
   "metadata": {},
   "source": [
    "Although the RL agent agrees with the rule-based DBA baseline in only 23.6% of cases, it achieves a significantly higher average reward (0.22 vs 0.055). This indicates that the agent learned a superior optimization strategy that goes beyond simple threshold-based heuristics, balancing performance gains and index costs more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b493d20f-1f38-4b44-b34a-2c3558ea7211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 15012, 1: 5988, 2: 0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48e7ff7b-65ab-4838-bea7-bf0617a201b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_counts = {\n",
    "    0: 15012,  # DO_NOTHING\n",
    "    1: 5988,   # ADD_INDEX\n",
    "    2: 0       # REMOVE_INDEX\n",
    "}\n",
    "\n",
    "actions = (\n",
    "    [0] * action_counts[0] +\n",
    "    [1] * action_counts[1] +\n",
    "    [2] * action_counts[2]\n",
    ")\n",
    "\n",
    "len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d6efa3d-03d9-4e73-9307-1879c44a97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d0cde-b8af-4d40-be67-0a6a33d71397",
   "metadata": {},
   "source": [
    "## Store the Decision logs in a data Frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2410a92-b19c-4c0a-9ea4-62ce6e106c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_log = []\n",
    "\n",
    "for i, action in enumerate(actions):\n",
    "    row = df_rl.iloc[i]\n",
    "\n",
    "    decision_log.append({\n",
    "        \"query_time\": row[\"query_time\"],\n",
    "        \"rows_examined\": row[\"rows_examined\"],\n",
    "        \"tables_count\": row[\"tables_count\"],\n",
    "        \"joins\": row[\"joins\"],\n",
    "        \"has_where\": row[\"has_where\"],\n",
    "        \"action\": env.action_meaning[action]\n",
    "    })\n",
    "\n",
    "df_decisions = pd.DataFrame(decision_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7267e89-ed44-4be8-ba1c-4c0b91ba8173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action\n",
       "DO_NOTHING    15012\n",
       "ADD_INDEX      5988\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decisions[\"action\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4f784c3-62d2-4e3d-8e52-19ceb632d43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>action</th>\n",
       "      <th>ADD_INDEX</th>\n",
       "      <th>DO_NOTHING</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.0, 0.05]</th>\n",
       "      <td>4266</td>\n",
       "      <td>10605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.05, 0.1]</th>\n",
       "      <td>1151</td>\n",
       "      <td>3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.1, 0.3]</th>\n",
       "      <td>571</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "action       ADD_INDEX  DO_NOTHING\n",
       "query_time                        \n",
       "(0.0, 0.05]       4266       10605\n",
       "(0.05, 0.1]       1151        3011\n",
       "(0.1, 0.3]         571        1396"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    pd.cut(df_decisions[\"query_time\"], [0, 0.05, 0.1, 0.3]),\n",
    "    df_decisions[\"action\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d597c56b-a6fa-4a2e-867b-bbca7d5992e7",
   "metadata": {},
   "source": [
    "The agent tends to favor ADD_INDEX even for fast queries due to consistent positive reward signals, highlighting the importance of stricter cost-aware reward shaping."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SADOP)",
   "language": "python",
   "name": "sadop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
